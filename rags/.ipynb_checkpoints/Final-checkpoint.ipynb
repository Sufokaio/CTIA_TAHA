{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from txtai.embeddings import Embeddings\n",
    "from txtai.pipeline import Extractor, LLM\n",
    "from txtai.pipeline import Textractor\n",
    "\n",
    "import subprocess\n",
    "import re\n",
    "import os\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = LLM(\"TheBloke/Mistral-7B-OpenOrca-GGUF/mistral-7b-openorca.Q4_K_M.gguf\", verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/tahaelhihi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing ./clustcontext994.txt\n",
      "Indexing ./regcontext994.txt\n"
     ]
    }
   ],
   "source": [
    "def stream(path):\n",
    "  for f in sorted(os.listdir(path)):\n",
    "    fpath = os.path.join(path, f)\n",
    "\n",
    "    if f.endswith((\"context994.txt\")):\n",
    "      print(f\"Indexing {fpath}\")\n",
    "      yield textractor(fpath)\n",
    "\n",
    "textractor = Textractor()\n",
    "\n",
    "\n",
    "embeddings = Embeddings(content=True)\n",
    "embeddings.index(stream(\".\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute(question, context):\n",
    "  prompt = f\"\"\"<|im_start|>system\n",
    "{context}\n",
    "\n",
    "<|im_end|>\n",
    "<|im_start|>user\n",
    "# Task:\n",
    "Analyze the input sentence and extract necessary elements according to the instructions given above. \n",
    "Make sure the output strictly follows the specified format without any additional words or deviations.\n",
    "Input:\n",
    "{question}\n",
    "\n",
    "<|im_end|>\n",
    "<|im_start|>assistant\n",
    "  \"\"\"\n",
    "\n",
    "  return llm(prompt, maxlength=4096)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def context(question):\n",
    "  results = embeddings.search(question)\n",
    "  if results:\n",
    "      context = results[0][\"text\"]\n",
    "  else:\n",
    "      context = \"No results found\"\n",
    "  return context\n",
    "\n",
    "def rag(question):\n",
    "  return execute(question, context(question))\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_intermediate(input_string):\n",
    "    cleaned_string = input_string.replace('\\n', ' ')\n",
    "    cleaned_string = re.sub(r'\\s+', ' ', cleaned_string)    \n",
    "    cleaned_string = re.sub(r'[^\\w\\s]', '', cleaned_string.strip())\n",
    "    cleaned_string = cleaned_string.lower()\n",
    "    words = cleaned_string.split()\n",
    "    return '[' + ', '.join(words) + ']'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_prolog_parser(input_string):\n",
    "    command = [\n",
    "        'swipl',  \n",
    "        '-g',\n",
    "        f\"phrase(parse(Commands, Attributes), {input_string}), writeln(Commands), writeln(Attributes),halt\",  \n",
    "        '-t',\n",
    "        'halt(0)',  \n",
    "        'parser.pl'  \n",
    "    ]\n",
    "\n",
    "    result = subprocess.run(command, stdout=subprocess.PIPE, text=True)\n",
    "    return result.stdout.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_to_AutoML_translator(query): \n",
    "    intermediate = rag(query)\n",
    "    cleaned_intermediate = clean_intermediate(intermediate)\n",
    "    output = call_prolog_parser(cleaned_intermediate)\n",
    "\n",
    "    output = output.split('\\n')\n",
    "\n",
    "    print(\"intermediate:\")\n",
    "    print(intermediate)\n",
    "    print('\\n')\n",
    "    \n",
    "    print(\"AutoML Symbols:\")\n",
    "    print(output[0])\n",
    "    \n",
    "    print(\"Data columns:\")\n",
    "    print(output[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML Symbols:\n",
      "Regression, dependent attribute: height, independent attributes: volume.\n",
      "\n",
      "\n",
      "AutoML Symbols:\n",
      "[loadData,calculateVolume,splitTrainTestData,knnRegression,regressionMSEError]\n",
      "Data columns:\n",
      "[[],[surfaceInSquareMeters,heightInMeters],[],[[volume],height],knnRegression_OUTPUT]\n"
     ]
    }
   ],
   "source": [
    "llm_to_AutoML_translator(\"Predict height based on volume through regression.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML Symbols:\n",
      "Clustering attributes: [volume]\n",
      "\n",
      "\n",
      "AutoML Symbols:\n",
      "[loadData,calculateVolume,clusterData,clusterCount]\n",
      "Data columns:\n",
      "[[],[surfaceInSquareMeters,heightInMeters],[volume],clusterData_OUTPUT]\n"
     ]
    }
   ],
   "source": [
    "llm_to_AutoML_translator(\"Given the objects dataset, how many types of objects can be found, according to their volume?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intermediate:\n",
      "Regression: dependent attribute: volume, independent attributes: surface.\n",
      "\n",
      "\n",
      "AutoML Symbols:\n",
      "[loadData,calculateVolume,splitTrainTestData,knnRegression,regressionMSEError]\n",
      "Data columns:\n",
      "[[],[surfaceInSquareMeters,heightInMeters],[],[[surface],volume],knnRegression_OUTPUT]\n"
     ]
    }
   ],
   "source": [
    "llm_to_AutoML_translator(\"Train a model that can estimate volume based on surface given the objects dataset.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML Symbols:\n",
      "Clustering attributes: volume, height\n",
      "\n",
      "\n",
      "AutoML Symbols:\n",
      "[loadData,calculateVolume,clusterData,clusterCount]\n",
      "Data columns:\n",
      "[[],[surfaceInSquareMeters,heightInMeters],[volume,height],clusterData_OUTPUT]\n"
     ]
    }
   ],
   "source": [
    "llm_to_AutoML_translator(\"How many different types of objects based on volume and height.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML Symbols:\n",
      "Regression:\n",
      "dependent attribute: mass,\n",
      "independent attributes: surface.\n",
      "\n",
      "\n",
      "AutoML Symbols:\n",
      "[loadData,splitTrainTestData,knnRegression,regressionMSEError]\n",
      "Data columns:\n",
      "[[],[],[[surface],mass],knnRegression_OUTPUT]\n"
     ]
    }
   ],
   "source": [
    "llm_to_AutoML_translator(\"Train a model that can estimate mass based on surface given the objects dataset.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML Symbols:\n",
      "Clustering attributes: mass.\n",
      "\n",
      "\n",
      "AutoML Symbols:\n",
      "[loadData,clusterData,clusterCount]\n",
      "Data columns:\n",
      "[[],[mass],clusterData_OUTPUT]\n"
     ]
    }
   ],
   "source": [
    "llm_to_AutoML_translator(\"Cluster objects based on mass.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML Symbols:\n",
      "Regression, dependent attribute: volume, independent attributes: surface, height.\n",
      "\n",
      "\n",
      "AutoML Symbols:\n",
      "[loadData,calculateVolume,splitTrainTestData,knnRegression,regressionMSEError]\n",
      "Data columns:\n",
      "[[],[surfaceInSquareMeters,heightInMeters],[],[[surface,height],volume],knnRegression_OUTPUT]\n"
     ]
    }
   ],
   "source": [
    "llm_to_AutoML_translator(\"Train a model that can estimate volume based on surface and height given the objects dataset.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intermediate:\n",
      "Regression, dependent attribute: volume, independent attributes: density.\n",
      "\n",
      "\n",
      "AutoML Symbols:\n",
      "[loadData,calculateVolume,calculateDensity,splitTrainTestData,knnRegression,regressionMSEError]\n",
      "Data columns:\n",
      "[[],[surfaceInSquareMeters,heightInMeters],[massInKilograms,surfaceInSquareMeters],[],[[density],volume],knnRegression_OUTPUT]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    " llm_to_AutoML_translator(\"Train a model that can estimate volume based on density given the objects dataset.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
