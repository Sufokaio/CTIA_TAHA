{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/envo/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/opt/anaconda3/envs/envo/lib/python3.8/site-packages/pydantic/_internal/_fields.py:151: UserWarning: Field \"model_list\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/envo/lib/python3.8/site-packages/pydantic/_internal/_fields.py:151: UserWarning: Field \"model_name\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/envo/lib/python3.8/site-packages/pydantic/_internal/_fields.py:151: UserWarning: Field \"model_group_alias\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/envo/lib/python3.8/site-packages/pydantic/_internal/_fields.py:151: UserWarning: Field \"model_info\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/envo/lib/python3.8/site-packages/pydantic/_internal/_fields.py:151: UserWarning: Field \"model_id\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from txtai.embeddings import Embeddings\n",
    "from txtai.pipeline import Extractor, LLM\n",
    "from txtai.pipeline import Textractor\n",
    "\n",
    "import subprocess\n",
    "import re\n",
    "import os\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = LLM(\"TheBloke/Mistral-7B-OpenOrca-GGUF/mistral-7b-openorca.Q4_K_M.gguf\", verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/tahaelhihi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-15 12:20:41,490 [MainThread  ] [INFO ]  Retrieving http://search.maven.org/remotecontent?filepath=org/apache/tika/tika-server-standard/2.6.0/tika-server-standard-2.6.0.jar to /var/folders/l8/3t_1vg_s3szb10t1rf49zq2w0000gn/T/tika-server.jar.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing ./clustcontext994.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-15 12:21:15,311 [MainThread  ] [INFO ]  Retrieving http://search.maven.org/remotecontent?filepath=org/apache/tika/tika-server-standard/2.6.0/tika-server-standard-2.6.0.jar.md5 to /var/folders/l8/3t_1vg_s3szb10t1rf49zq2w0000gn/T/tika-server.jar.md5.\n",
      "2024-05-15 12:21:16,280 [MainThread  ] [WARNI]  Failed to see startup log message; retrying...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing ./regcontext994.txt\n"
     ]
    }
   ],
   "source": [
    "def stream(path):\n",
    "  for f in sorted(os.listdir(path)):\n",
    "    fpath = os.path.join(path, f)\n",
    "\n",
    "    if f.endswith((\"context994.txt\")):\n",
    "      print(f\"Indexing {fpath}\")\n",
    "      yield textractor(fpath)\n",
    "\n",
    "textractor = Textractor()\n",
    "\n",
    "\n",
    "embeddings = Embeddings(content=True)\n",
    "embeddings.index(stream(\".\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute(question, context):\n",
    "  prompt = f\"\"\"<|im_start|>system\n",
    "{context}\n",
    "\n",
    "<|im_end|>\n",
    "<|im_start|>user\n",
    "# Task:\n",
    "Analyze the input sentence and extract necessary elements according to the instructions given above. \n",
    "Make sure the output strictly follows the specified format without any additional words or deviations.\n",
    "Input:\n",
    "{question}\n",
    "\n",
    "<|im_end|>\n",
    "<|im_start|>assistant\n",
    "  \"\"\"\n",
    "\n",
    "  return llm(prompt, maxlength=4096)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def context(question):\n",
    "  results = embeddings.search(question)\n",
    "  if results:\n",
    "      context = results[0][\"text\"]\n",
    "  else:\n",
    "      context = \"No results found\"\n",
    "  return context\n",
    "\n",
    "def rag(question):\n",
    "  return execute(question, context(question))\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_intermediate(input_string):\n",
    "    cleaned_string = input_string.replace('\\n', ' ')\n",
    "    cleaned_string = re.sub(r'\\s+', ' ', cleaned_string)    \n",
    "    cleaned_string = re.sub(r'[^\\w\\s]', '', cleaned_string.strip())\n",
    "    cleaned_string = cleaned_string.lower()\n",
    "    words = cleaned_string.split()\n",
    "    return '[' + ', '.join(words) + ']'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_prolog_parser(input_string):\n",
    "    command = [\n",
    "        'swipl',  \n",
    "        '-g',\n",
    "        f\"phrase(parse(Commands, Attributes), {input_string}), writeln(Commands), writeln(Attributes),halt\",  \n",
    "        '-t',\n",
    "        'halt(0)',  \n",
    "        'parser.pl'  \n",
    "    ]\n",
    "\n",
    "    result = subprocess.run(command, stdout=subprocess.PIPE, text=True)\n",
    "    return result.stdout.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_to_AutoML_translator(query): \n",
    "    intermediate = rag(query)\n",
    "    cleaned_intermediate = clean_intermediate(intermediate)\n",
    "    output = call_prolog_parser(cleaned_intermediate)\n",
    "\n",
    "    output = output.split('\\n')\n",
    "\n",
    "    print(\"intermediate:\")\n",
    "    print(intermediate)\n",
    "    print('\\n')\n",
    "    \n",
    "    print(\"AutoML Symbols:\")\n",
    "    print(output[0])\n",
    "    \n",
    "    print(\"Data columns:\")\n",
    "    print(output[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intermediate:\n",
      "Regression:\n",
      "   dependent attribute: height,\n",
      "   independent attributes: volume.\n",
      "\n",
      "\n",
      "AutoML Symbols:\n",
      "[loadData,calculateVolume,splitTrainTestData,knnRegression,regressionMSEError]\n",
      "Data columns:\n",
      "[[],[surfaceInSquareMeters,heightInMeters],[],[[volume],height],knnRegression_OUTPUT]\n"
     ]
    }
   ],
   "source": [
    "llm_to_AutoML_translator(\"Predict height based on volume through regression.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intermediate:\n",
      "Clustering attributes: volume\n",
      "\n",
      "\n",
      "AutoML Symbols:\n",
      "[loadData,calculateVolume,clusterData,clusterCount]\n",
      "Data columns:\n",
      "[[],[surfaceInSquareMeters,heightInMeters],[volume],clusterData_OUTPUT]\n"
     ]
    }
   ],
   "source": [
    "llm_to_AutoML_translator(\"Given the objects dataset, how many types of objects can be found, according to their volume?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intermediate:\n",
      "Regression, dependent attribute: volume, independent attributes: surface.\n",
      "\n",
      "\n",
      "AutoML Symbols:\n",
      "[loadData,calculateVolume,splitTrainTestData,knnRegression,regressionMSEError]\n",
      "Data columns:\n",
      "[[],[surfaceInSquareMeters,heightInMeters],[],[[surface],volume],knnRegression_OUTPUT]\n"
     ]
    }
   ],
   "source": [
    "llm_to_AutoML_translator(\"Train a model that can estimate volume based on surface given the objects dataset.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intermediate:\n",
      "Clustering attributes: volume, height.\n",
      "\n",
      "\n",
      "AutoML Symbols:\n",
      "[loadData,calculateVolume,clusterData,clusterCount]\n",
      "Data columns:\n",
      "[[],[surfaceInSquareMeters,heightInMeters],[volume,height],clusterData_OUTPUT]\n"
     ]
    }
   ],
   "source": [
    "llm_to_AutoML_translator(\"How many different types of objects based on volume and height.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intermediate:\n",
      "Regression:\n",
      "   dependent attribute: mass,\n",
      "   independent attributes: surface\n",
      "\n",
      "\n",
      "AutoML Symbols:\n",
      "[loadData,splitTrainTestData,knnRegression,regressionMSEError]\n",
      "Data columns:\n",
      "[[],[],[[surface],mass],knnRegression_OUTPUT]\n"
     ]
    }
   ],
   "source": [
    "llm_to_AutoML_translator(\"Train a model that can estimate mass based on surface given the objects dataset.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intermediate:\n",
      "Clustering attributes: mass.\n",
      "\n",
      "\n",
      "AutoML Symbols:\n",
      "[loadData,clusterData,clusterCount]\n",
      "Data columns:\n",
      "[[],[mass],clusterData_OUTPUT]\n"
     ]
    }
   ],
   "source": [
    "llm_to_AutoML_translator(\"Cluster objects based on mass.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intermediate:\n",
      "Regression, dependent attribute: volume, independent attributes: mass, surface, height.\n",
      "\n",
      "\n",
      "AutoML Symbols:\n",
      "[loadData,calculateVolume,splitTrainTestData,knnRegression,regressionMSEError]\n",
      "Data columns:\n",
      "[[],[surfaceInSquareMeters,heightInMeters],[],[[mass,surface,height],volume],knnRegression_OUTPUT]\n"
     ]
    }
   ],
   "source": [
    "llm_to_AutoML_translator(\"Train a model that can estimate volume based on surface and height given the objects dataset.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intermediate:\n",
      "Regression, dependent attribute: volume, independent attributes: density.\n",
      "\n",
      "\n",
      "AutoML Symbols:\n",
      "[loadData,calculateVolume,calculateDensity,splitTrainTestData,knnRegression,regressionMSEError]\n",
      "Data columns:\n",
      "[[],[surfaceInSquareMeters,heightInMeters],[massInKilograms,surfaceInSquareMeters],[],[[density],volume],knnRegression_OUTPUT]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "llm_to_AutoML_translator(\"Train a model that can estimate volume based on density given the objects dataset.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intermediate:\n",
      "Regression, dependent attribute: mass, independent attributes: surface, density.\n",
      "\n",
      "\n",
      "AutoML Symbols:\n",
      "[loadData,calculateDensity,splitTrainTestData,knnRegression,regressionMSEError]\n",
      "Data columns:\n",
      "[[],[massInKilograms,surfaceInSquareMeters],[],[[surface,density],mass],knnRegression_OUTPUT]\n"
     ]
    }
   ],
   "source": [
    "llm_to_AutoML_translator(\"Predict mass using attributes such as surface and density given the objects dataset.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intermediate:\n",
      "Regression, dependent attribute: density, independent attributes: volume, mass.\n",
      "\n",
      "\n",
      "AutoML Symbols:\n",
      "[loadData,calculateDensity,calculateVolume,splitTrainTestData,knnRegression,regressionMSEError]\n",
      "Data columns:\n",
      "[[],[massInKilograms,surfaceInSquareMeters],[surfaceInSquareMeters,heightInMeters],[],[[volume,mass],density],knnRegression_OUTPUT]\n"
     ]
    }
   ],
   "source": [
    "llm_to_AutoML_translator(\"Train a model that can estimate density based on volume and mass given the objects dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intermediate:\n",
      "Regression, dependent attribute: density, independent attributes: mass\n",
      "\n",
      "\n",
      "AutoML Symbols:\n",
      "[loadData,calculateDensity,splitTrainTestData,knnRegression,regressionMSEError]\n",
      "Data columns:\n",
      "[[],[massInKilograms,surfaceInSquareMeters],[],[[mass],density],knnRegression_OUTPUT]\n"
     ]
    }
   ],
   "source": [
    "llm_to_AutoML_translator(\"Train a model that can estimate density based on mass given the objects dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
